import json
import uuid
import sqlite3
import time
from contextlib import closing
from pika.exceptions import ChannelClosedByBroker, StreamLostError, AMQPError

from base64 import b64decode
from io import BytesIO
from PIL import Image
import requests
import base64
from typing import List, Dict, Optional
from openai import OpenAI

from static.rabbitmq import *
from static.model import *
from static.s3 import *
from static.classifier_preprompt import SYSTEM_INSTRUCTIONS, TOOLS

from styletransfer.tasks import wait_for_result


IDEMPOTENT_DB_PATH = os.environ.get("IDEMPOTENT_DB_PATH", "/db/processed.db")
os.makedirs(os.path.dirname(IDEMPOTENT_DB_PATH), exist_ok=True)
with closing(sqlite3.connect(IDEMPOTENT_DB_PATH)) as conn:
    conn.execute("""
        CREATE TABLE IF NOT EXISTS processed (
            request_id TEXT PRIMARY KEY,
            status TEXT NOT NULL,
            updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
        )
    """)
    conn.commit()

def mark_in_progress(request_id: str) -> bool:
    """ì•„ì§ ì²˜ë¦¬ë˜ì§€ ì•Šì•˜ìœ¼ë©´ ê¸°ë¡ í›„ True, ì´ë¯¸ ìˆìœ¼ë©´ False"""
    try:
        with closing(sqlite3.connect(IDEMPOTENT_DB_PATH, timeout=5)) as conn:
            conn.execute("BEGIN IMMEDIATE")
            row = conn.execute("SELECT status FROM processed WHERE request_id=?", (request_id,)).fetchone()
            if row and row[0] in ("done", "in_progress"):
                conn.commit()
                return False
            conn.execute("INSERT OR REPLACE INTO processed(request_id, status, updated_at) VALUES(?,?,CURRENT_TIMESTAMP)",
                         (request_id, "in_progress"))
            conn.commit()
            return True
    except sqlite3.Error:
        return True  # DB ë¬¸ì œ ì‹œì—ë„ ì²˜ë¦¬ ì§„í–‰

def mark_done(request_id: str):
    try:
        with closing(sqlite3.connect(IDEMPOTENT_DB_PATH, timeout=5)) as conn:
            conn.execute("INSERT OR REPLACE INTO processed(request_id, status, updated_at) VALUES(?,?,CURRENT_TIMESTAMP)",
                         (request_id, "done"))
            conn.commit()
    except sqlite3.Error:
        pass

def safe_publish(channel, routing_key, body, max_retries=3, sleep_sec=0.5):
    """RabbitMQ publish ì¬ì‹œë„"""
    for attempt in range(1, max_retries + 1):
        try:
            channel.basic_publish(exchange='', routing_key=routing_key, body=body)
            return True
        except (ChannelClosedByBroker, StreamLostError, AMQPError, OSError) as e:
            print(f"[ê²½ê³ ] publish ì‹¤íŒ¨({attempt}/{max_retries}): {e}")
            time.sleep(sleep_sec)
    return False

def get_client() -> OpenAI:
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise RuntimeError("í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    return OpenAI(api_key=API_KEY)


def get_s3_key():
    image_name = uuid.uuid4().hex
    extension = "png"
    filename = f"{image_name}.{extension}"
    prefix = S3_PATH_PREFIX.strip('/')
    s3_key = f"{prefix}/{filename}"
    return s3_key, filename, image_name, extension


def upload_to_s3(image_bytes):
    s3_key, filename, image_name, extension = get_s3_key()
    s3_client.put_object(
        Bucket=S3_BUCKET,
        Key=s3_key,
        Body=image_bytes,
        ContentType="image/png"
    )
    return s3_key, filename, image_name, extension


def open_binary(image_path: str):
    print(image_path)
    key = image_path.lstrip("/")
    resp = s3_client.get_object(Bucket=S3_BUCKET, Key=key)  # <-- Key=key ë¡œ!
    data = resp["Body"].read()
    fname = os.path.basename(key)
    ctype = resp.get("ContentType", "image/png")  # S3ì— ì €ì¥í•œ ContentType ì¬ì‚¬ìš©
    return fname, BytesIO(data), ctype


def generate_image_from_text(prompt: str, size: str = "1024x1024") -> Image.Image:
    """
    OpenAI Images API(gpt-image-1)ë¡œ í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë¥¼ ë³´ë‚´ê³ 
    base64ë¡œ ë°›ì€ ì´ë¯¸ì§€ë¥¼ PIL.Imageë¡œ ë°˜í™˜
    """
    resp = client.images.generate(
        model=IMAGES_MODEL,
        prompt=prompt,
        size="auto",
    )
    b64 = resp.data[0].b64_json
    img = Image.open(BytesIO(b64decode(b64)))
    return img


def edit_image_from_text(
    image_path: str,
    prompt: str,
    size: str = "1024x1024",
    mask_path: Optional[str] = None,
    reference_image_paths: Optional[List[str]] = None,
    style_image_path: Optional[str] = None,
    api_key: Optional[str] = None,
) -> Image.Image:
    """
    OpenAI Images API (gpt-image-1) í¸ì§‘ í˜¸ì¶œ.
    - image_path: í¸ì§‘ì˜ 'ë² ì´ìŠ¤' ì´ë¯¸ì§€ (í•„ìˆ˜)
    - mask_path: íˆ¬ëª… PNG ë§ˆìŠ¤í¬ (ì„ íƒ)
    - reference_image_paths: ì°¸ê³  ì´ë¯¸ì§€ ê²½ë¡œ/URL ë¦¬ìŠ¤íŠ¸ (ì„ íƒ)
    - style_image_path: ìŠ¤íƒ€ì¼ ê°€ì´ë“œ ì´ë¯¸ì§€ ê²½ë¡œ/URL (ì„ íƒ)
    - size: '256x256' | '512x512' | '1024x1024'
    â€» ì°¸ê³ /ìŠ¤íƒ€ì¼ ì´ë¯¸ì§€ëŠ” OpenAI í¸ì§‘ ì—”ë“œí¬ì¸íŠ¸ì—ì„œ ë„¤ì´í‹°ë¸Œ ê°€ì´ë“œë¡œ ì“°ì´ì§€ ì•Šì„ ìˆ˜ ìˆìŒ.
      ì´ë¥¼ ë³´ì™„í•˜ê¸° ìœ„í•´ promptì— ëª…ì‹œì ìœ¼ë¡œ íŒíŠ¸ë¥¼ ì£¼ì…í•˜ë©°, íŒŒì¼ íŒŒíŠ¸ëŠ” ref_image_#/style_imageë¡œ í•¨ê»˜ ì „ì†¡.
    """
    api_key = api_key or os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise RuntimeError("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    url = "https://api.openai.com/v1/images/edits"
    headers = {"Authorization": f"Bearer {api_key}"}

    files = {}

    # í•„ìˆ˜: base image
    base_name, base_fh, base_ct = open_binary(image_path)
    files["image"] = (base_name, base_fh, base_ct)

    # ì„ íƒ: mask
    if mask_path:
        mask_name, mask_fh, mask_ct = open_binary(mask_path)
        files["mask"] = (mask_name, mask_fh, mask_ct)

    # ì„ íƒ: reference images (ì—¬ëŸ¬ ì¥)
    ref_list = reference_image_paths or []

    # ì°¸ê³ /ìŠ¤íƒ€ì¼ ì•ˆë‚´ë¥¼ í”„ë¡¬í”„íŠ¸ì— ì£¼ì…
    ref_hint = ""
    if ref_list:
        ref_hint += f" ì°¸ê³ ì´ë¯¸ì§€ {len([r for r in ref_list if r])}ì¥ì„ ë°˜ì˜í•´ í¸ì§‘í•˜ë¼."

    effective_prompt = (prompt or "").strip()
    if ref_hint:
        effective_prompt = (effective_prompt + " " + ref_hint).strip()

    data = {
        "model": "gpt-image-1",
        "prompt": effective_prompt,
        "size": size,
    }

    resp = requests.post(url, headers=headers, files=files, data=data, timeout=120)
    if not resp.ok:
        print("[OpenAI error payload]", resp.status_code, resp.text)
    resp.raise_for_status()

    # íŒŒì¼ ì •ë¦¬
    base_fh.close()
    if mask_path:
        mask_fh.close()

    b64 = resp.json()["data"][0]["b64_json"]
    return Image.open(BytesIO(base64.b64decode(b64)))


def do_style_transfer(style_image_path, content_image):
    style_name, style_image, style_type = open_binary(style_image_path)
    result_image = wait_for_result(content_image, style_image, prompt=None, preprocessor=None)
    if result_image is None:
        return None

    return result_image

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3) í•¸ë“¤ëŸ¬
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def execute_image_task(
    *,
    prompt: Optional[str],
    subtype: str,
    base_path: Optional[str],            # NEW
    extra_refs: List[str],               # NEW
    generate_instructions: Optional[str],
    edit_instructions: Optional[str],
    style_transfer: bool,
    style_image_path: Optional[str] = None,
) -> (bool, str, object):
    def _pil_to_bytesio(img: Image.Image) -> BytesIO:
        buf = BytesIO()
        img.save(buf, format="PNG")
        buf.seek(0)
        return buf

    def _bytesio_to_pil(fp: BytesIO) -> Image.Image:
        fp.seek(0)
        im = Image.open(fp)
        return im.convert("RGB") if im.mode != "RGB" else im

    # ì¶œë ¥ ê²½ë¡œ ì¤€ë¹„
    os.makedirs("outputs", exist_ok=True)
    existing = [f for f in os.listdir("outputs") if f.startswith("img_") and f.endswith(".png")]
    out_path = os.path.join("outputs", f"img_{len(existing)+1:03d}.png")

    print("Subtype: ", subtype)
    # ìƒì„±
    if subtype == "generate":
        gen_text = (generate_instructions or prompt or "").strip()
        if not gen_text:
            print("[ì—ëŸ¬] generate í”„ë¡¬í”„íŠ¸ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
            return False, f"[ì—ëŸ¬] generate í”„ë¡¬í”„íŠ¸ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.", None
        print(f"[ìƒì„±] prompt={gen_text!r}")
        try:
            img = generate_image_from_text(gen_text, size="1024x1024")
            img.save(out_path)
            print(f"[ì™„ë£Œ] ìƒì„± ì´ë¯¸ì§€ ì €ì¥: {out_path}")

            # ìŠ¤íƒ€ì¼ ë³€í™˜
            if style_transfer and style_image_path:
                content_fp = _pil_to_bytesio(img)
                result_fp = do_style_transfer(style_image_path, content_fp)
                print(f"[ì •ë³´] style_transfer=True, style_image_path={style_image_path}")
                if result_fp is None:
                    return False, f"[ì´ë¯¸ì§€ ìƒì„± ë‹¨ê³„, ìŠ¤íƒ€ì¼ ë³€í™˜ ì—ëŸ¬]", None
                img = _bytesio_to_pil(result_fp)

            return True, "", img
        except Exception as e:
            print(f"[ì—ëŸ¬]: {e}")
            return False, f"[ì—ëŸ¬]: {e}", None

    # í¸ì§‘ ì§€ì‹œë¬¸
    edit_text = (edit_instructions or "").strip()
    if not edit_text:
        edit_text = "ì´ë¯¸ì§€ë¥¼ ê°œì„ í•´ì¤˜"

    print(f"[í¸ì§‘] base={base_path}, refs={extra_refs}, instr={edit_text!r}")
    try:
        if subtype in ("edit", "style_transfer") and not base_path:
            return False, "[ì—ëŸ¬] base_pathê°€ ë¹„ì—ˆìŠµë‹ˆë‹¤.", None

        if subtype == "edit":
            img = edit_image_from_text(
                image_path=base_path,
                prompt=edit_text,
                size="auto",
                mask_path=None,
                reference_image_paths=extra_refs,
                style_image_path=None,
            )

            # ìŠ¤íƒ€ì¼ ë³€í™˜
            if style_transfer:
                if not style_image_path:
                    return False, "[ì—ëŸ¬] ìŠ¤íƒ€ì¼ ë³€í™˜ ìš”ì²­ì´ì§€ë§Œ style_image_pathê°€ ì—†ìŠµë‹ˆë‹¤.", None
                content_fp = _pil_to_bytesio(img)
                result_fp = do_style_transfer(style_image_path, content_fp)
                print(f"[ì •ë³´] style_transfer=True, style_image_path={style_image_path}")
                if result_fp is None:
                    return False, f"[ìŠ¤íƒ€ì¼ ë³€í™˜ ì—ëŸ¬]", None
                img = _bytesio_to_pil(result_fp)

        elif subtype == "style_transfer":
            if not style_image_path:
                return False, "[ì—ëŸ¬] ìŠ¤íƒ€ì¼ ë³€í™˜ ìš”ì²­ì´ì§€ë§Œ style_image_pathê°€ ì—†ìŠµë‹ˆë‹¤.", None
            _, content_fh, _ = open_binary(base_path)
            content_fh.seek(0)
            result_fp = do_style_transfer(style_image_path, content_fh)
            if result_fp is None:
                return False, "[ìŠ¤íƒ€ì¼ ë³€í™˜ ì—ëŸ¬]", None
            img = _bytesio_to_pil(result_fp)

        else:
            return False, f"[Image task subtype Error: {subtype}]", None

    except Exception as e:
        print(f"[ì—ëŸ¬] í¸ì§‘ ì‹¤íŒ¨: {e}")
        return False, f"[ì—ëŸ¬] í¸ì§‘ ì‹¤íŒ¨: {e}", None

    img.save(out_path)
    print(f"[ì™„ë£Œ] í¸ì§‘ ì´ë¯¸ì§€ ì €ì¥: {out_path}")

    return True, "", img


def classify_and_execute(
    prompt: str,
    images_path: list,
    style_image_id: str,
    style_image_path: str,
    recent_chat: list,
    chat_summary: str,
    model: str = MODEL,
):
    """
    í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ë¥¼ 'ê°™ì€ ë©”ì‹œì§€'ì˜ content ë°°ì—´ë¡œ ì„ì–´ ì „ë‹¬.
    - chat ë‚´ í…ìŠ¤íŠ¸/ì´ë¯¸ì§€ë¥¼ turn ìˆœì„œëŒ€ë¡œ ë„£ê³ ,
    - uploads(images_path)ëŠ” ë³„ë„ ì„¹ì…˜ìœ¼ë¡œ ì´ì–´ì„œ ë„£ìŒ.
    - ê° ì´ë¯¸ì§€ëŠ” ë¼ë²¨(chat#i / upload#j)ì„ í…ìŠ¤íŠ¸ë¡œ ë¨¼ì € ëª…ì‹œí•˜ê³ , ë°”ë¡œ ë‹¤ìŒì— image_url ë¡œ ì‹¤ì œ ì´ë¯¸ì§€ë¥¼ ì²¨ë¶€.
    - TOOLì€ indices(=chat ì´ë¯¸ì§€ ì¸ë±ìŠ¤ë§Œ), reference_urls(file://, chat/ì—…ë¡œë“œ ëª¨ë‘)ì— ë§ì¶° ì‘ë‹µ.
    """

    def _safe(s):
        return (s or "").replace("\n", " ").strip()

    def _bool(v):
        if v is True or v is False:
            return v
        if isinstance(v, str):
            t = v.strip().lower()
            if t in ("true", "1", "yes", "y"): return True
            if t in ("false", "0", "no", "n"): return False
        raise ValueError(f"bool ê°’ì´ ì˜ëª»ë¨ {v}")

    def _is_http(u: str) -> bool:
        return isinstance(u, str) and u.startswith("https://")

    def _json_text_block(obj: dict):
        return {
            "type": "text",
            "text": json.dumps(obj, ensure_ascii=False)
        }

    def _resolve_item(item, chat_image_map, uploads):
        """item: {source: 'chat'|'upload', index?:int, path?:str} -> ì‹¤ì œ ê²½ë¡œ(str)"""
        if not item or "source" not in item:
            return None
        src = item["source"]
        idx = item.get("index", None)
        pth = item.get("path", None)

        if src == "chat":
            if isinstance(idx, int) and (idx in chat_image_map):
                return chat_image_map[idx]
            return pth  # (fallback)
        if src == "upload":
            if isinstance(idx, int) and 0 <= idx < len(uploads):
                return uploads[idx]
            return pth  # (fallback)
        return None

    # 1) ê°„ë‹¨í•œ ì„¤ëª…ê³¼ ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ (ë¹„ì–´ìˆìœ¼ë©´ ë¹ˆ ë¬¸ìì—´ë¡œ)
    content = [{
        "type": "text",
        "text": (
            "ì•„ë˜ëŠ” í•˜ë‚˜ì˜ JSON ê¸°ë°˜ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤.\n"
            "- prompt: ì´ë²ˆ ìš”ì²­ì˜ ì‚¬ìš©ì í…ìŠ¤íŠ¸\n"
            "- chat_images: ê³¼ê±° ëŒ€í™” ì¤‘ ì´ë¯¸ì§€ ëª©ë¡ (chat#i)\n"
            "- uploads: ì´ë²ˆ ìš”ì²­ì— í¬í•¨ëœ ì—…ë¡œë“œ ì´ë¯¸ì§€ ëª©ë¡ (S3 Key ë˜ëŠ” URL)\n"
            "- chat_summary: ì´ì „ ëŒ€í™”ì˜ ìš”ì•½ (ì„ íƒ)\n"
            "âš  ëª¨ë“  í•­ëª©ì€ JSON ê°ì²´ë¡œ ì œê³µë˜ë©°, ì‚¬ëŒ ì½ê¸°ìš© í…ìŠ¤íŠ¸ëŠ” í¬í•¨ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n"
            "íˆ´ì€ prompt / chat_images / uploadsë¥¼ ê¸°ë°˜ìœ¼ë¡œ base ë° referencesë¥¼ ê²°ì •í•´ì•¼ í•©ë‹ˆë‹¤."
        )
    }, _json_text_block({
        "type": "prompt",
        "value": _safe(prompt)
    })]

    # 2) recent_chatì—ì„œ ì´ë¯¸ì§€ë§Œ êµ¬ì¡°í™” (i ì¸ë±ìŠ¤ëŠ” chat#iì™€ ë™ì¼í•˜ê²Œ ë¶€ì—¬)
    chat_image_map: Dict[int, str] = {}
    chat_images = []
    img_counter = 0

    for turn in list(recent_chat or []):
        role = turn.get("role", "user")
        for c in turn.get("contents", []):
            ctype = (c.get("type") or "").lower()
            if ctype == "image":
                img_path = _safe(c.get("imagePath", ""))
                desc = _safe(c.get("description", ""))
                from_origin_image = _bool(c.get("fromOriginImage"))
                if not img_path:
                    continue
                chat_images.append({
                    "i": img_counter,  # â† indices[0]ë¡œ ê³ ë¥¼ ë•Œ ì‚¬ìš©í•  ì •ìˆ˜ ì¸ë±ìŠ¤
                    "path": img_path,  # â† S3 í‚¤ or https URL (ê·¸ëŒ€ë¡œ ì‚¬ìš©)
                    "role": role,  # user/assistant
                    "description": desc,  # ì„ íƒ ì„¤ëª…
                    "fromOriginImage": from_origin_image  # bool
                })
                chat_image_map[img_counter] = img_path
                img_counter += 1

    # chat ì´ë¯¸ì§€ ëª©ë¡ì„ JSON ë¸”ë¡ìœ¼ë¡œ ì „ë‹¬
    content.append(_json_text_block({
        "type": "chat_images",
        "value": chat_images  # []ì¼ ìˆ˜ ìˆìŒ
    }))

    # 3) ì—…ë¡œë“œ ëª©ë¡ì„ JSON ë¸”ë¡ìœ¼ë¡œ ì „ë‹¬ (ì‚¬ëŒìš© ë¼ë²¨ ì œê±°)
    uploads = [_safe(p) for p in (images_path or [])]
    content.append(_json_text_block({
        "type": "uploads",
        "value": uploads  # ì˜ˆ: ["ai-request/...."] ë˜ëŠ” []
    }))

    # (ì„ íƒ) chat_summaryë„ ê¸°ê³„ê°€ ì½ê¸° ì‰½ê²Œ JSONìœ¼ë¡œë§Œ ì „ë‹¬
    if chat_summary:
        content.append(_json_text_block({
            "type": "chat_summary",
            "value": _safe(chat_summary)
        }))

    # ë””ë²„ê·¸ ë¡œê·¸ë„ JSONë§Œ ì°ê¸°
    print({
        "prompt": _safe(prompt),
        "chat_images_count": len(chat_images),
        "uploads": uploads
    })

    # â”€â”€ 5) route_scenario í˜¸ì¶œ: í…ìŠ¤íŠ¸+ì´ë¯¸ì§€ í•¨ê»˜ ì „ë‹¬
    resp = client.chat.completions.create(
        model=model,
        messages=[
            {"role": "system", "content": SYSTEM_INSTRUCTIONS},
            {"role": "user", "content": content},  # í•œ ë©”ì‹œì§€ì— text+image ë™ì‹œ í¬í•¨
        ],
        tools=TOOLS,
        tool_choice={"type": "function", "function": {"name": "route_scenario"}},
        temperature=0.2,
    )
    # â”€â”€ 6) íˆ´ ì•„ì›ƒí’‹ íŒŒì‹±
    choice = resp.choices[0]
    msg = choice.message
    tool_calls = msg.tool_calls or []
    if not tool_calls:
        print("[ê²½ê³ ] íˆ´ í˜¸ì¶œì´ ê°ì§€ë˜ì§€ ì•ŠìŒ.")
        if msg.content:
            print(f"[ëª¨ë¸í…ìŠ¤íŠ¸]: {msg.content}")
        return "error", f"[ëª¨ë¸í…ìŠ¤íŠ¸]: {msg.content}"

    call = tool_calls[0]
    raw = call.function.arguments
    try:
        args = json.loads(raw) if isinstance(raw, str) else raw
    except Exception:
        print(f"[ì—ëŸ¬] arguments JSON íŒŒì‹± ì‹¤íŒ¨: {raw}")
        return "error", f"[ì—ëŸ¬] arguments JSON íŒŒì‹± ì‹¤íŒ¨: {raw}"

    new_chat_summary = args.get("chat_summary", chat_summary)

    # â”€â”€ 7) ê²°ê³¼ í•´ì„ (ì´ë¯¸ì§€ ì‘ì—…ë§Œ ìˆ˜í–‰)
    needs = bool(args.get("needs_clarification", False))
    reason = args.get("reason", "")
    if needs:
        print(f"ì¶”ê°€ì ì¸ ì„¤ëª… í•„ìš”, ì´ìœ : {reason}")
        message = {"response": f"{reason}", "chat_summary": new_chat_summary, "reason": reason}
        return "clarify", message

    subtype = args.get("subtype")  # "generate" | "edit" | "style_transfer"

    # NEW: base/references êµ¬ì¡° í•´ì„ ìœ í‹¸
    uploads = [_safe(p) for p in (images_path or [])]  # ì´ë¯¸ ìœ„ì—ì„œ ë§Œë“  ê°’ê³¼ ë™ì¼ ê°œë…

    # NEW: base / references í•´ì„
    base_obj = args.get("base")
    base_path = _resolve_item(base_obj, chat_image_map, uploads)

    ref_objs = args.get("references", []) or []
    extra_refs = []
    for r in ref_objs:
        rp = _resolve_item(r, chat_image_map, uploads)
        if rp:
            extra_refs.append(rp)

    generation_prompt = args.get("generate_instructions") or prompt
    edit_instructions = args.get("edit_instructions")
    style_transfer = bool(args.get("style_transfer", False))
    image_description = args.get("image_description", "")

    # í•„ìˆ˜ ê²€ì¦: í¸ì§‘/ìŠ¤íƒ€ì¼ ë³€í™˜ì´ë©´ base í•„ìˆ˜
    if subtype in ("edit", "style_transfer") and not base_path:
        print("[ê²½ê³ ] í¸ì§‘/ìŠ¤íƒ€ì¼ ë³€í™˜ì¸ë° base ë¯¸ì§€ì • â†’ clarifyë¡œ ì „í™˜")
        message = {"response": "í¸ì§‘/ìŠ¤íƒ€ì¼ ë³€í™˜ì¸ë° base ì´ë¯¸ì§€ë¥¼ íŠ¹ì •í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.",
                   "chat_summary": new_chat_summary,
                   "reason": "baseê°€ ë¹„ì—ˆìŠµë‹ˆë‹¤. ìµœê·¼ ì—…ë¡œë“œ ë˜ëŠ” ìµœì‹  USER ì´ë¯¸ì§€ë¥¼ baseë¡œ ì‚¬ìš©í• ì§€ ì„ íƒí•´ ì£¼ì„¸ìš”."}
        return "clarify", message

    print(f"[ë¶„ë¥˜] action=image task(ê³ ì •), subtype={subtype}, needs={needs}, style_transfer={style_transfer}")
    print(f"[ëŒ€ìƒ base] {base_path}")
    if extra_refs:
        print(f"[ì°¸ì¡° refs] {extra_refs}")

    # â”€â”€ 8) ì´ë¯¸ì§€ ì‘ì—… ì‹¤í–‰
    payload = {
        "prompt": prompt,
        "subtype": (subtype or "generate"),
        "base_path": base_path,  # NEW
        "extra_refs": extra_refs,  # NEW
        "generate_instructions": (generation_prompt if subtype == "generate" else None),
        "edit_instructions": (edit_instructions if (subtype != "generate") else None),
        "style_transfer": style_transfer,
        "style_image_path": style_image_path,
    }

    success, message, img = execute_image_task(**payload)
    if not success:
        return "error", message
    try:
        buf = BytesIO()
        img.save(buf, format="PNG")
        buf.seek(0)
        s3_key, file_name, image_name, _ = upload_to_s3(buf.getvalue())

        from_origin_image = False
        if isinstance(base_obj, dict) and base_obj.get("fromOriginImage") is True:
            from_origin_image = True

        for ref in ref_objs:
            if isinstance(ref, dict) and ref.get("fromOriginImage") is True:
                from_origin_image = True
                break

        message = {
            "image_path": s3_key,
            "file_name": file_name,
            "image_name": image_name,
            "description": image_description,
            "style_transfer": style_transfer,
            "chat_summary": new_chat_summary,
            "fromOriginImage": from_origin_image or style_transfer,
        }
        return "ok", message
    except Exception as e:
        print(e)
        return "error", e

def on_message(channel, method, properties, body):
    try:
        raw_body = body.decode("utf-8")
        print("[ğŸ“¥] ì‘ì—… ìˆ˜ì‹ :", raw_body)
        task = json.loads(raw_body)

        request_id = task.get("requestId")
        if not request_id:
            print("[ê²½ê³ ] requestId ì—†ìŒ â†’ DLXë¡œ ì´ë™")
            channel.basic_nack(delivery_tag=method.delivery_tag, requeue=False)
            return

        # [PATCH] ë©±ë“±ì„± ì²´í¬
        if not mark_in_progress(request_id):
            print(f"[ë©±ë“±] ì´ë¯¸ ì²˜ë¦¬ëœ ìš”ì²­ {request_id} â†’ ACK í›„ ìŠ¤í‚µ")
            channel.basic_ack(delivery_tag=method.delivery_tag)
            return

        prompt = task.get("prompt", "")
        images_path = task.get("imagesPath", [])
        style_image_id = task.get("styleImageId", "")
        style_image_path = task.get("styleImagePath", "")
        recent_chat = task.get("chat", [])
        chat_summary = task.get("chatSummary", "")

        success, message = classify_and_execute(
            prompt, images_path, style_image_id, style_image_path, recent_chat, chat_summary
        )

        # [PATCH] ìƒíƒœë³„ ì‘ë‹µ ì²˜ë¦¬
        if success == "ok":
            resp = {
                "isSuccess": True,
                "requestId": request_id,
                "isImageGenerated": True,
                "imagePath": message["image_path"],
                "fullImageName": message["file_name"],
                "imageName": message["image_name"],
                "extension": "PNG",
                "description": message["description"],
                "chatSummary": message["chat_summary"],
                "fromStyleImage": message["from_origin_image"]
            }
            if safe_publish(channel, IMAGE_GENERATION_CHAT_RESPONSE_QUEUE, json.dumps(resp)):
                mark_done(request_id)
                channel.basic_ack(delivery_tag=method.delivery_tag)
            else:
                print("[ì—ëŸ¬] publish ì‹¤íŒ¨ â†’ DLXë¡œ ì´ë™")
                channel.basic_nack(delivery_tag=method.delivery_tag, requeue=False)

        elif success == "clarify":
            resp = {
                "isSuccess": True,
                "requestId": request_id,
                "isImageGenerated": False,
                "textContext": message["reason"],
                "chatSummary": message["chat_summary"]
            }
            if safe_publish(channel, IMAGE_GENERATION_CHAT_RESPONSE_QUEUE, json.dumps(resp)):
                mark_done(request_id)
                channel.basic_ack(delivery_tag=method.delivery_tag)
            else:
                channel.basic_nack(delivery_tag=method.delivery_tag, requeue=False)

        else:
            print(f"[ì—ëŸ¬] ì²˜ë¦¬ ì‹¤íŒ¨: {success} / {message}")
            channel.basic_nack(delivery_tag=method.delivery_tag, requeue=False)

    except Exception as e:
        print(f"[âŒ] on_message ì˜ˆì™¸: {e}")
        channel.basic_nack(delivery_tag=method.delivery_tag, requeue=False)


def main():
    import ssl
    import pika
    import time

    while True:
        connection = None
        channel = None
        try:
            context = ssl.create_default_context()
            credentials = pika.PlainCredentials(IMAGE_GENERATION_CHAT_USERNAME, IMAGE_GENERATION_CHAT_PASSWORD)
            params = pika.ConnectionParameters(
                host=IMAGE_GENERATION_CHAT_HOST,
                port=int(IMAGE_GENERATION_CHAT_PORT),
                credentials=credentials,
                ssl_options=pika.SSLOptions(context),
                heartbeat=120,
                blocked_connection_timeout=300,
                client_properties={"connection_name": "image-consumer"},
            )
            connection = pika.BlockingConnection(params)
            channel = connection.channel()
            channel.basic_qos(prefetch_count=1)
            channel.confirm_delivery()

            channel.queue_declare(
                queue=IMAGE_GENERATION_CHAT_QUEUE,
                durable=True,
                arguments={
                    "x-dead-letter-exchange": "ai.image.request.dlx",
                    "x-dead-letter-routing-key": "ai.image.request.retry"
                }
            )

            channel.basic_consume(
                queue=IMAGE_GENERATION_CHAT_QUEUE,
                on_message_callback=on_message,
                auto_ack=False
            )

            print("[ğŸš€] ì´ë¯¸ì§€ ìƒì„± ì‘ì—… ëŒ€ê¸° ì¤‘...")
            channel.start_consuming()

        except KeyboardInterrupt:
            print("[ğŸ§©] ì‚¬ìš©ì ì¢…ë£Œ ìš”ì²­")
            break
        except Exception as e:
            print(f"[ê²½ê³ ] ì†Œë¹„ì ë£¨í”„ ì˜ˆì™¸ ë°œìƒ: {e}")
            time.sleep(2.0)
            continue
        finally:
            if channel and channel.is_open:
                try:
                    channel.stop_consuming()
                except:
                    pass
            if connection and not connection.is_closed:
                connection.close()
            print("[âœ”] ì—°ê²° ì¢…ë£Œ")


if __name__ == "__main__":
    client = get_client()
    main()
